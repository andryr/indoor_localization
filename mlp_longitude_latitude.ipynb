{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "c866b1f9-0dde-4b88-be2a-55b2e66e1702",
    "_uuid": "f4c9456e-054b-4119-9708-54e32fc891b1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "whole_train_df = pd.read_csv('uji_wifi/UJIndoorLoc/trainingData.csv')\n",
    "test_df = pd.read_csv('uji_wifi/UJIndoorLoc/ValidationData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the training data into training and validation sets using the USERID field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "c58450c5-b4cc-4cc6-9b60-e91a9fce0022",
    "_uuid": "9c374539-cb8b-407f-8192-dc6ddaafa203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15647, 529) (4290, 529)\n"
     ]
    }
   ],
   "source": [
    "train_mask = whole_train_df['USERID'] <= 13\n",
    "train_df = whole_train_df[train_mask]\n",
    "val_df = whole_train_df[~train_mask]\n",
    "print(train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put the data into NumPy arrays and set to -100dBm the values corresponding to absent AP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "3b414227-bbeb-46b7-bcd3-deaf6f471b5b",
    "_uuid": "971b7556-25d1-45b6-86a5-881620275e76"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_X = train_df.iloc[:,0:520].to_numpy()\n",
    "train_building = train_df[\"BUILDINGID\"].to_numpy(dtype=np.int64)\n",
    "train_floor = train_df[\"FLOOR\"].to_numpy(dtype=np.int64)\n",
    "train_long = train_df[\"LONGITUDE\"].to_numpy()\n",
    "train_lat = train_df[\"LATITUDE\"].to_numpy()\n",
    "\n",
    "val_X = val_df.iloc[:,0:520].to_numpy()\n",
    "val_building = val_df[\"BUILDINGID\"].to_numpy(dtype=np.int64)\n",
    "val_floor = val_df[\"FLOOR\"].to_numpy(dtype=np.int64)\n",
    "val_long = val_df[\"LONGITUDE\"].to_numpy()\n",
    "val_lat = val_df[\"LATITUDE\"].to_numpy()\n",
    "\n",
    "test_X = test_df.iloc[:,0:520].to_numpy()\n",
    "test_building = test_df[\"BUILDINGID\"].to_numpy(dtype=np.int64)\n",
    "test_floor = test_df[\"FLOOR\"].to_numpy(dtype=np.int64)\n",
    "test_long = test_df[\"LONGITUDE\"].to_numpy()\n",
    "test_lat = test_df[\"LATITUDE\"].to_numpy()\n",
    "\n",
    "\n",
    "train_X[train_X == 100] = -110\n",
    "val_X[val_X == 100] = -110\n",
    "test_X[test_X == 100] = -110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "7cb0bb18-24d9-4aa9-a45b-aefca31a8a94",
    "_uuid": "b94158b2-3ddc-44bb-bcaa-9dabfbc03ed1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def accuracy(pred_Y, true_Y):\n",
    "    return np.sum(pred_Y == true_Y)/len(true_Y)\n",
    "\n",
    "def distance_rmse(pred_long, pred_lat, true_long, true_lat):\n",
    "    sq_dist = (pred_long - true_long)**2 + (pred_lat - true_lat)**2\n",
    "    return np.sqrt(np.sum(sq_dist)/len(sq_dist))\n",
    "\n",
    "def dist_mean_error(pred_long, pred_lat, true_long, true_lat):\n",
    "    dist = np.sqrt((pred_long - true_long)**2 + (pred_lat - true_lat)**2)\n",
    "    return np.sum(dist)/len(pred_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following architecture is used for longitude/latitude estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "dbf369c3-d3c6-43ab-88a5-944e65091dde",
    "_uuid": "8b200c4b-acbb-49c3-a911-f650716d9e46"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_outputs=2):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(520, 256) \n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.linear2 = nn.Linear(256, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.linear4 = nn.Linear(128, 128)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.linear5 = nn.Linear(128, 64)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.linear6 = nn.Linear(64, 32)\n",
    "        self.bn6 = nn.BatchNorm1d(32)\n",
    "    \n",
    "\n",
    "        self.final = nn.Linear(32, num_outputs)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.linear2(x)))\n",
    "        x = F.leaky_relu(self.bn3(self.linear3(x)))\n",
    "        x = F.leaky_relu(self.bn4(self.linear4(x)))\n",
    "        x = F.leaky_relu(self.bn5(self.linear5(x)))\n",
    "        x = F.leaky_relu(self.bn6(self.linear6(x)))\n",
    "    \n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "66cb8164-52f3-44fa-afbb-1367be8d597e",
    "_uuid": "9baf4210-9056-4d6e-b1da-e1a14166efca"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs, patience=10, transform=None):\n",
    "    data_loaders = {'train': train_loader, 'val': val_loader}\n",
    "    data_lengths = {'train': len(train_loader), 'val': len(val_loader)}\n",
    "    best_val_loss = None\n",
    "    epochs_no_improve = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        epoch_start = time.time()\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(data_loaders[phase]):   \n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.cuda(),targets.cuda()\n",
    "                if phase == 'train' and transform is not None:\n",
    "                    inputs = transform(inputs)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs).squeeze(-1) \n",
    "                loss = criterion(outputs,targets)  \n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward() \n",
    "                    optimizer.step() \n",
    "\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            epoch_loss = running_loss/data_lengths[phase]\n",
    "            if phase == 'train':\n",
    "                print(f'Training loss : {epoch_loss}')\n",
    "                print(f'Learning rate : {optimizer.param_groups[0][\"lr\"]}')\n",
    "            else:\n",
    "                scheduler.step(epoch_loss)\n",
    "                print(f'Validation loss : {epoch_loss}')\n",
    "                if best_val_loss is None or epoch_loss < best_val_loss:\n",
    "                    epochs_no_improve = 0\n",
    "                    best_val_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= patience:\n",
    "                        print('Early stopping')\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                        return model\n",
    "                \n",
    "        print(f'Epoch duration : {time.time() - epoch_start}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "0e3ecc76-3f80-4f8a-b6f6-0efdf32d367b",
    "_uuid": "d38a8c48-9ad2-424a-a017-3590f88717b3"
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(normalize_rssi(X), dtype=torch.float32).cuda()\n",
    "        outputs = model(inputs).squeeze(-1)\n",
    "        return outputs.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs and outputs are normalized. If outputs were not normalized, the performance are not good because of the batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "5f96cb96-9d63-4202-be44-794c3f9d4f0b",
    "_uuid": "2ff47879-7144-4b51-bd58-8cbec1124a38"
   },
   "outputs": [],
   "source": [
    "def normalize_rssi(rssi):\n",
    "    return (110 + rssi)/110\n",
    "\n",
    "def normalize_longitude(longitude):\n",
    "    return (-longitude - 7299) / 395\n",
    "\n",
    "def denormalize_longitude(norm_long):\n",
    "    return -(norm_long * 395 + 7299)\n",
    "\n",
    "def normalize_latitude(latitude):\n",
    "    return  (latitude -  4864745)/218\n",
    "\n",
    "def denormalize_latitude(norm_lat):\n",
    "    return 218*norm_lat + 4864745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White Gaussian noise is added to inputs in order to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "6bfef117-10da-47b5-bdb6-02efa043b6f9",
    "_uuid": "879d72c7-1988-475c-b8e8-4f4e18da41a2"
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise:\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()).cuda() * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "fd0557cc-4772-4997-9301-a92502c52e8b",
    "_uuid": "5dc6cf62-646b-498c-b092-3a369601834d"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "long_tensor = torch.tensor(normalize_longitude(train_long), dtype=torch.float32)\n",
    "lat_tensor = torch.tensor(normalize_latitude(train_lat), dtype=torch.float32)\n",
    "\n",
    "target_tensor = torch.cat((long_tensor.view(-1,1), lat_tensor.view(-1,1)), 1)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(normalize_rssi(train_X), dtype=torch.float32), target_tensor), batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "long_tensor = torch.tensor(normalize_longitude(val_long), dtype=torch.float32)\n",
    "lat_tensor = torch.tensor(normalize_latitude(val_lat), dtype=torch.float32)\n",
    "\n",
    "target_tensor = torch.cat((long_tensor.view(-1,1), lat_tensor.view(-1,1)), 1)\n",
    "\n",
    "val_loader = DataLoader(TensorDataset(torch.tensor(normalize_rssi(val_X), dtype=torch.float32), target_tensor), batch_size=128, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "9cff1840-8d48-4f11-a491-85c73c79f4d9",
    "_uuid": "9261ae3e-87d4-4e0b-890a-650141384cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training loss : 0.08317833221555362\n",
      "Learning rate : 0.001\n",
      "Validation loss : 0.0038095085867954526\n",
      "Epoch duration : 1.5143654346466064\n",
      "Epoch 2\n",
      "Training loss : 0.0030909818114440253\n",
      "Learning rate : 0.001\n",
      "Validation loss : 0.0024131135672659557\n",
      "Epoch duration : 1.520348310470581\n",
      "Epoch 3\n",
      "Training loss : 0.002246985155653693\n",
      "Learning rate : 0.001\n",
      "Validation loss : 0.0028846086660290465\n",
      "Epoch duration : 1.5291497707366943\n",
      "Epoch 4\n",
      "Training loss : 0.0017390344907128351\n",
      "Learning rate : 0.001\n",
      "Validation loss : 0.002067970029790612\n",
      "Epoch duration : 1.6027476787567139\n",
      "Epoch 5\n",
      "Training loss : 0.0015796988713176452\n",
      "Learning rate : 0.001\n",
      "Validation loss : 0.001591394521871253\n",
      "Epoch duration : 1.7394757270812988\n",
      "Epoch 6\n",
      "Training loss : 0.0013378017025477275\n",
      "Learning rate : 0.001\n",
      "Validation loss : 0.0015606194022385513\n",
      "Epoch duration : 1.5787162780761719\n",
      "Epoch 7\n",
      "Training loss : 0.0012396121249965777\n",
      "Learning rate : 0.001\n",
      "Validation loss : 0.001972234948291717\n",
      "Epoch duration : 1.5911250114440918\n",
      "Epoch 8\n",
      "Training loss : 0.0013023542987496963\n",
      "Learning rate : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-127:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 498, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 742, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-09e3479def27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-c054db48159c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs, patience, transform)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_SIGCHLD_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_pids_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;31m# prime the prefetch loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefetch_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36m_start_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doing self._thread.start()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... done self._thread.start()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "mlp = MLP(num_outputs=2).cuda()\n",
    "\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "mlp = train(mlp, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs=200, patience=20, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ac539edc-0022-414b-85e6-fddb213755a3",
    "_uuid": "485835a9-9282-46e7-9f7a-b0a3f4ade98e"
   },
   "outputs": [],
   "source": [
    "val_pred = predict(mlp, val_X)\n",
    "val_pred_long = denormalize_longitude(val_pred[:,0])\n",
    "val_pred_lat = denormalize_latitude(val_pred[:,1])\n",
    "\n",
    "long_rmse = mean_squared_error(val_pred_long, val_long, squared=False)\n",
    "lat_rmse = mean_squared_error(val_pred_lat, val_lat, squared=False)\n",
    "dist_rmse = distance_rmse(val_pred_long, val_pred_lat, val_long, val_lat)\n",
    "dist_me = dist_mean_error(val_pred_long, val_pred_lat, val_long, val_lat)\n",
    "\n",
    "print('Val longitude RMSE : ', long_rmse)\n",
    "print('Val latitude RMSE : ', lat_rmse)\n",
    "print('Val distance RMSE : ', dist_rmse)\n",
    "print('Val distance ME : ', dist_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e14cc9c-aebb-46c1-b2ec-4afd6427dd84",
    "_uuid": "85acfcd2-7726-4989-a527-88d187f3da3c"
   },
   "outputs": [],
   "source": [
    "test_pred = predict(mlp, test_X)\n",
    "test_pred_long = denormalize_longitude(test_pred[:,0])\n",
    "test_pred_lat = denormalize_latitude(test_pred[:,1])\n",
    "\n",
    "long_rmse = mean_squared_error(test_pred_long, test_long, squared=False)\n",
    "lat_rmse = mean_squared_error(test_pred_lat, test_lat, squared=False)\n",
    "dist_rmse = distance_rmse(test_pred_long, test_pred_lat, test_long, test_lat)\n",
    "dist_me = dist_mean_error(test_pred_long, test_pred_lat, test_long, test_lat)\n",
    "\n",
    "print('Test longitude RMSE : ', long_rmse)\n",
    "print('Test latitude RMSE : ', lat_rmse)\n",
    "print('Test distance RMSE : ', dist_rmse)\n",
    "print('Test distance ME : ', dist_me)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
